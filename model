import numpy as np
from matplotlib import pyplot
from numpy import interp
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import precision_recall_curve
import pandas as pd
from sklearn.utils import shuffle
import matplotlib.pyplot as plt
from sklearn import metrics
import scipy.io
from keras import utils
from keras import layers, models
from keras.models import Model
from keras.layers import Dense, Dropout, Input, Activation, BatchNormalization
from keras.callbacks import EarlyStopping
from keras.utils import np_utils
from keras.optimizers import Adam
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import label_binarize
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split

from sklearn.svm import SVC
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import label_binarize
from deepforest import CascadeForestClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import ExtraTreesClassifier

import numpy as np
from sklearn import preprocessing
from numpy import matlib


def load_data():
    ID = np.loadtxt(r'C:\Users\HuXiang\Desktop\CFSAEMDA\data\SD.txt')
    IM = np.loadtxt(r'C:\Users\HuXiang\Desktop\CFSAEMDA\data\SM.txt')


    return ID, IM




def prepare_data():
    print("loading data")
    
    
    SD, SM = load_data()
    

    A = np.loadtxt(r"C:\Users\HuXiang\Desktop\CFSAEMDA\data\interaction.txt", dtype=int, delimiter=" ")
    interacation = np.transpose(A)

    R_B = matlib.repmat(interacation, 495, 1)
    sm = np.repeat(SM, repeats=383, axis=0)
    train1 = np.concatenate((sm, R_B), axis=1)  # (189585,990)

    R_A = np.repeat(A, repeats=383, axis=0)
    sd = matlib.repmat(SD, 495, 1)
    train2 = np.concatenate((R_A, sd), axis=1)  # (189585,766)
    label = A.reshape((189585, 1))

    return train1, train2, label


def transfer_array_format(data):  # data=X  , X= all the miRNA features, disease features
    formated_matrix1 = []
    formated_matrix2 = []
    for val in data:
        formated_matrix1.append(val[0])  # contains miRNA features ?
        formated_matrix2.append(val[1])  # contains disease features ?

    return np.array(formated_matrix1), np.array(formated_matrix2)


def preprocess_labels(labels, encoder=None, categorical=True):
    if not encoder:
        encoder = preprocessing.LabelEncoder()
        encoder.fit(labels)
    y = encoder.transform(labels).astype(np.int32)
    if categorical:
        y = utils.np_utils.to_categorical(y)
    return y, encoder


mtrain, dtrain, label = prepare_data()
m, encoder = preprocess_labels(label)
nm = np.arange(len(m))
m = m[nm]
    
m_data2 = pd.DataFrame(mtrain)
d_data2 = pd.DataFrame(dtrain)


X_1 = pd.concat([m_data2,d_data2],axis=1)
X_1 = np.array(X_1)

label_1 = pd.DataFrame(label)

XY = pd.concat([m_data2,d_data2, label_1],axis=1)
X = XY.iloc[:,0:1756] # 获取特征数据
y = XY.iloc[:,1756] # 获取标签

#对数据进行平衡
number_records_fraud = len(y[y==1])# 标签为1的样本数量，异常样本的数量
print(len(y[y==1])) 
print(len(y[y==0])) # 标签为0的样本数量，正常样本的数量

fraud_indices = y[y==1].index # 获取标签为1的样本的索引
normal_indices = y[y==0].index # 获取标签为0的样本的索引

random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=False) # 随机从class=0的样本中拿number_records_fraud个数据
random_normal_indices = np.array(random_normal_indices)

under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])
under_sample_data = XY.iloc[under_sample_indices, :]

under_sample_data = shuffle(under_sample_data)
under_sample_data = shuffle(under_sample_data)

XX = under_sample_data.iloc[:,0:1756] # 获取特征数据
m = under_sample_data.iloc[:,1756] # 获取标签
m = np.array(m)

m, encoder = preprocess_labels(m)
nm = np.arange(len(m))
m = m[nm]


#降维
def miRNA_auto_encoder(x_train):
    input_img = layers.Input(shape=(1756,))
    # 建立神经网络
    # 编码层
    encoded = layers.Dense(1024, activation='tanh')(input_img)
    # 解码层

    decoded = layers.Dense(1756, activation='tanh')(encoded)
    # 构建自编码模型
    autoencoder = models.Model(inputs=input_img, outputs=decoded)
    encoder = models.Model(inputs=input_img, outputs=encoded)
    # 激活模型
    adam = Adam(learning_rate=0.001)
    autoencoder.compile(optimizer=adam, loss='mse')
    autoencoder.fit(x_train, x_train, epochs=20, batch_size=512, shuffle=True)
    miRNA_encoded_imgs = encoder.predict(x_train)
    return miRNA_encoded_imgs

def miRNA_auto_encoder2(x_train):
    input_img = layers.Input(shape=(1024,))
    # 建立神经网络
    # 编码层
    encoded = layers.Dense(512, activation='tanh')(input_img)
    # 解码层

    decoded = layers.Dense(1024, activation='tanh')(encoded)
    # 构建自编码模型
    autoencoder = models.Model(inputs=input_img, outputs=decoded)
    encoder = models.Model(inputs=input_img, outputs=encoded)
    # 激活模型
    adam = Adam(learning_rate=0.001)
    autoencoder.compile(optimizer=adam, loss='mse')
    autoencoder.fit(x_train, x_train, epochs=20, batch_size=512, shuffle=True)
    miRNA_encoded_imgs = encoder.predict(x_train)
    return miRNA_encoded_imgs

def miRNA_auto_encoder3(x_train):
    input_img = layers.Input(shape=(512,))
    # 建立神经网络
    # 编码层
    encoded = layers.Dense(256, activation='tanh')(input_img)
    # 解码层

    decoded = layers.Dense(512, activation='tanh')(encoded)
    # 构建自编码模型
    autoencoder = models.Model(inputs=input_img, outputs=decoded)
    encoder = models.Model(inputs=input_img, outputs=encoded)
    # 激活模型
    adam = Adam(learning_rate=0.001)
    autoencoder.compile(optimizer=adam, loss='mse')
    autoencoder.fit(x_train, x_train, epochs=20, batch_size=512, shuffle=True)
    miRNA_encoded_imgs = encoder.predict(x_train)
    return miRNA_encoded_imgs

from sklearn.svm import SVC
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import label_binarize
from deepforest import CascadeForestClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import ExtraTreesClassifier
def ad_compute_indexes(tp, fp, tn, fn,y_test,y_prob_score):
    from sklearn import metrics
    precision_1, recall_1, pr_threshods = metrics.precision_recall_curve(y_test,y_prob_score,pos_label=1)
    aupr_score = metrics.auc(recall_1, precision_1)
    acc = float(tp + tn) / (tp+tn+fp+fn) 
    sensitivity = float(tp) / (tp + fn)
    specificity = float(tn) / (tn + fp)
    precision = float(tp) / (tp + fp)
    MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))
    f1_score = float(2 * tp) / ((2 * tp) + fp + fn)
    return acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score

def transfer_label_from_prob(proba):
    label = [1 if val >= 0.5 else 0 for val in proba]
    return label
    
X_2 =miRNA_auto_encoder(XX)
X_3 =miRNA_auto_encoder2(X_2)
X =miRNA_auto_encoder3(X_3)
X = np.array(X)  
    

def transfer_label_from_prob(proba):
    label = [1 if val >= 0.5 else 0 for val in proba]
    return label


X_train,X_test,y_train,y_test = train_test_split(X,m,test_size=0.2,random_state=0)    
    
num_cross = 4
all_performance = []
t = 0
probaresult = []
ae_y_pred_probresult = []


mean_tpr = 0.0
tprs=[]
aucs=[]
mean_fpr = np.linspace(0, 1, 100)

y_real1 = []
y_proba1 = []

X_train = np.array(X_train)

for fold in range(num_cross):
    print(fold)
    train_X = np.array([x for i, x in enumerate(X_train) if i % num_cross != fold])
    test_X = np.array([x for i, x in enumerate(X_train) if i % num_cross == fold])

    train_label = np.array([x for i, x in enumerate(y_train) if i % num_cross != fold])
    train_label_new = [] #训练标签
    for val in train_label:
        if val[0] == 1:
            train_label_new.append(0)
        else:
            train_label_new.append(1)

    test_label = np.array([x for i, x in enumerate(y_train) if i % num_cross == fold])
    real_labels = [] #测试标签
    for val in test_label:
        if val[0] == 1:  # tuples in array, val[0]- first element of tuple
            real_labels.append(0)
        else:
            real_labels.append(1)


     #分类器，模型

    clf = CascadeForestClassifier(random_state=1,verbose=0,n_jobs=-1)
    estimators = [RandomForestClassifier(random_state=1,n_jobs=-1,n_estimators=100),
                 XGBClassifier(random_state=1,n_jobs=-1,n_estimators=100),
                 ExtraTreesClassifier(random_state=1,n_jobs=-1,n_estimators=100),
                  LGBMClassifier(random_state=1,n_jobs=-1,n_estimators=100)]
    clf.set_estimator(estimators)
    predictor = SVC(random_state=1,probability=True,kernel='poly')
    clf.set_predictor(predictor)
    #print(train_X)
    print('---' * 20)
    clf.fit(train_X, train_label_new)
    X_y_pred_prob = clf.predict_proba(test_X)[:, 1]
    Xproba = transfer_label_from_prob(X_y_pred_prob)


    proba = Xproba

    #预测的最终概率，使用平均法
    ae_y_pred_prob = X_y_pred_prob
    #结果保存
    probaresult.extend(proba) 
    ae_y_pred_probresult.extend(ae_y_pred_prob)

    y_test = real_labels
    y_pred = transfer_label_from_prob(ae_y_pred_prob)

    #混淆矩阵
    tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred,labels=[1,0]).ravel()

    acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score = ad_compute_indexes(tp, fp, tn, fn,y_test,ae_y_pred_prob)
    fpr, tpr, _= metrics.roc_curve(real_labels,ae_y_pred_prob)
    auc = metrics.auc(fpr, tpr)

    print('---' * 20)
    print(metrics.confusion_matrix(y_test, y_pred,labels=[1,0]))
    print(acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score,auc)

    all_performance.append([acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score,auc])

    tprs.append(interp(mean_fpr,fpr,tpr))
    tprs[-1][0]=0.0
    aucs.append(auc)   

    #AUPR
    precision2, recall2, _2 = metrics.precision_recall_curve(real_labels,ae_y_pred_prob)
    scipy.io.savemat(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\CFSAEMDA_AUPR_%d.mat'%(fold)
                        , {'recall': recall2, 'precision': precision2, 'mean_aupr': aupr_score})
    y_real1.append(real_labels)
    y_proba1.append(ae_y_pred_prob)
    #AUC
    scipy.io.savemat(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\CFSAEMDA_AUC_%d.mat'%(fold)
                         , {'fpr': fpr, 'tpr': tpr, 'mean_auc': auc})


#画对角线
plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',label='Luck',alpha=0.8)

mean_tpr=np.mean(tprs,axis=0)
mean_tpr[-1]=1.0
mean_auc=metrics.auc(mean_fpr,mean_tpr)#计算平均AUC值

scipy.io.savemat(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\CFSAEMDA_AUC.mat'
                         , {'mean_fpr': mean_fpr, 'mean_tpr': mean_tpr, 'mean_auc': mean_auc})

y_real1 = np.concatenate(y_real1)
y_proba1 = np.concatenate(y_proba1)
precision3, recall3, _3 = metrics.precision_recall_curve(y_real1, y_proba1)




Mean_Result = np.mean(np.array(all_performance), axis=0)
std_auc=np.std(tprs,axis=0)
plt.plot(recall3,precision3,color='b',label=r'Mean ROC (area=%0.4f)'%Mean_Result[7],lw=2,alpha=.8)
std_tpr=np.std(tprs,axis=0)
tprs_upper=np.minimum(mean_tpr+std_tpr,1)
tprs_lower=np.maximum(mean_tpr-std_tpr,0)
#plt.fill_between(mean_tpr,tprs_lower,tprs_upper,color='gray',alpha=.2)
plt.xlim([-0.05,1.05])
plt.ylim([-0.05,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC')
plt.legend(loc='lower right')
plt.show() 



print('---' * 20)
print('Mean-acc=', Mean_Result[0], '\n Mean-precision=', Mean_Result[1])
print('Mean-sensitivity=', Mean_Result[2], '\n Mean-specificity=', Mean_Result[3])
print('Mean-MCC=', Mean_Result[4], '\n Mean-f1_score=', Mean_Result[5])

print('Mean-aupr_score=', Mean_Result[6], '\n Mean-auc=', Mean_Result[7])

stu = ['acc', 'precision', 'sensitivity', 'specificity', 'MCC', 'f1_score','aupr_score','auc']


#注意修改文件名称，确保数据

scipy.io.savemat(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\CFSAEMDA_AUPR.mat'
                         , {'recall': recall3, 'precision': precision3, 'mean_aupr': Mean_Result[6]})
Mean_Result = pd.DataFrame(Mean_Result,index=stu)
Mean_Result.to_csv(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\CFSAEMDA.csv',sep=',',index=True,header=False)

#使用测试集对模型进行评价

X_train,X_test,y_train,y_test = train_test_split(X,m,test_size=0.2,random_state=0)
clf = CascadeForestClassifier(random_state=1,verbose=0,n_jobs=-1)
estimators = [RandomForestClassifier(random_state=1,n_jobs=-1,n_estimators=100),
             XGBClassifier(random_state=1,n_jobs=-1,n_estimators=100),
             ExtraTreesClassifier(random_state=1,n_jobs=-1,n_estimators=100),
              LGBMClassifier(random_state=1,n_jobs=-1,n_estimators=100)]
clf.set_estimator(estimators)
predictor = SVC(random_state=1,probability=True,kernel='poly')
clf.set_predictor(predictor)

probaresult = []
ae_y_pred_probresult = []

train_X = np.array(X_train)
train_label = np.array(y_train)
train_label_new = [] #训练标签
for val in train_label:
    if val[0] == 1:
        train_label_new.append(0)
    else:
        train_label_new.append(1)
        
clf.fit(train_X, train_label_new)

test_X = np.array(X_test)
test_label = np.array(y_test)
test_label_new = [] #训练标签
for val in test_label:
    if val[0] == 1:
        test_label_new.append(0)
    else:
        test_label_new.append(1)

X_y_pred_prob = clf.predict_proba(test_X)[:, 1]
Xproba = transfer_label_from_prob(X_y_pred_prob)

proba = Xproba

#预测的最终概率，使用平均法
ae_y_pred_prob = X_y_pred_prob
#结果保存
probaresult.extend(proba) 
ae_y_pred_probresult.extend(ae_y_pred_prob)

y_test = test_label_new
y_pred = transfer_label_from_prob(ae_y_pred_prob)

all_performance = []
tprs=[]
aucs=[]
#混淆矩阵
tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred,labels=[1,0]).ravel()

acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score = ad_compute_indexes(tp, fp, tn, fn,y_test,ae_y_pred_prob)
fpr, tpr, _= metrics.roc_curve(test_label_new,ae_y_pred_prob)
auc = metrics.auc(fpr, tpr)

print('---' * 20)
print(metrics.confusion_matrix(y_test, y_pred,labels=[1,0]))
print(acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score,auc)

all_performance.append([acc, precision, sensitivity, specificity, MCC, f1_score,aupr_score,auc])


#AUPR
precision2, recall2, _2 = metrics.precision_recall_curve(test_label_new,ae_y_pred_prob)
scipy.io.savemat(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\AUPR_CFSAEMDA_测试集.mat'
                    , {'recall': recall2, 'precision': precision2, 'mean_aupr': aupr_score})

#AUC
scipy.io.savemat(r'C:\Users\HuXiang\Desktop\CFSAEMDA\result\AUC_CFSAEMDA_测试集.mat'
                     , {'fpr': fpr, 'tpr': tpr, 'mean_auc': auc})
